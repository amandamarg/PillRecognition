{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from benchmark.metrics import MetricsCollection\n",
    "import torch.nn as nn\n",
    "from evaluate import LogitsEvaluator, EmbeddingEvaluator\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CustomBatchSamplerPillID, PillImages\n",
    "from benchmark.pillid_datasets import SingleImgPillID, BalancedBatchSamplerPillID, SiamesePillID\n",
    "import utils\n",
    "from benchmark.models.multihead_model import MultiheadModel\n",
    "from benchmark.models.embedding_model import EmbeddingModel\n",
    "from benchmark.models.losses import MultiheadLoss\n",
    "from benchmark.metric_utils import HardNegativePairSelector, RandomNegativeTripletSelector\n",
    "from train import Trainer\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_df, fold_indicies = utils.load_data()\n",
    "ref_df = all_imgs_df[all_imgs_df.is_ref].reset_index(drop=True)\n",
    "# unique_classes = all_imgs_df['label'].unique()\n",
    "unique_classes = ref_df[\"label\"].unique()\n",
    "all_imgs_df = all_imgs_df[all_imgs_df[\"label\"].isin(unique_classes)].reset_index(drop=True) \n",
    "n_classes = len(unique_classes)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_classes)\n",
    "partitions = utils.split_data(all_imgs_df, fold_indicies)\n",
    "datasets = utils.get_datasets(partitions, ref_df, 'label', False, label_encoder=label_encoder)\n",
    "dataloaders = {}\n",
    "for k,v in datasets.items():\n",
    "    dataloaders[k] = DataLoader(v, batch_sampler=CustomBatchSamplerPillID(v.df, 32, labelcol='label', min_classes=5, min_per_class=2, keep_remainders=True, batch_size_mode=None, debug=False))\n",
    "eval_dataset = PillImages(pd.concat([partitions['val'], ref_df]), \"eval\", labelcol=\"label\", label_encoder=label_encoder)\n",
    "dataloaders[\"eval\"] = DataLoader(eval_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b637eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated with copilot\n",
    "def clear_directory(directory):\n",
    "    \"\"\"\n",
    "    Recursively deletes all files and subdirectories in the specified directory using os.walk.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(directory, topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9424b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with batch sampler from dataset.py\n",
    "torch.mps.empty_cache()\n",
    "log_file_path = \"./benchmark_training_logs\"\n",
    "writer = SummaryWriter(log_file_path)\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "appearance_network = 'resnet50'\n",
    "pooling = 'GAvP'\n",
    "dropout = 0.0\n",
    "embedding_dim = 2048\n",
    "ce_w = 1.0\n",
    "arcface_w = 0.1\n",
    "contrastive_w = 1.0 \n",
    "triplet_w = 1.0\n",
    "focal_w = 0.0\n",
    "loss_weights = {'ce': ce_w, 'arcface': arcface_w, 'contrastive': contrastive_w, 'triplet': triplet_w, 'focal': focal_w}\n",
    "focal_gamma = 0.0\n",
    "metric_margin = 1.0\n",
    "train_with_side_labels = False\n",
    "train_with_ref_labels = False\n",
    "clip_grads = True\n",
    "simulate_pairs = False\n",
    "shift_labels = False\n",
    "path = \"./\"\n",
    "criterion = MultiheadLoss(len(label_encoder.classes_),\n",
    "            metric_margin, HardNegativePairSelector(),\n",
    "            metric_margin, RandomNegativeTripletSelector(metric_margin),\n",
    "            use_cosine=False,\n",
    "            weights=loss_weights,\n",
    "            focal_gamma=focal_gamma,\n",
    "            use_side_labels=train_with_side_labels)\n",
    "E_model = EmbeddingModel(network=appearance_network, pooling=pooling, dropout_p=dropout, cont_dims=embedding_dim, pretrained=True)\n",
    "model = MultiheadModel(E_model, n_classes, train_with_side_labels=train_with_side_labels).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)\n",
    "trainer = Trainer(device=device, model=model, dataloaders=dataloaders, clip_gradients=clip_grads, optimizer=opt, lr_scheduler=lr_scheduler, criterion=criterion, writer=writer, eval_update_type=\"logit\", metric_type=\"euclidean\", simulate_pairs=simulate_pairs, shift_labels=shift_labels, train_with_ref_labels=train_with_ref_labels, plot_metrics_names=[\"acc_1\", \"acc_5\", \"loss\", \"micro_ap\", \"map\", \"mrr\"], path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_directory(log_file_path)\n",
    "clear_directory(\"./checkpoints\")\n",
    "trainer.train(num_epochs=10, checkpoint=3, earlystop_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with batch sampler from benchmark.pillid_dataset.py (https://github.com/usuyama/ePillID-benchmark)\n",
    "dataloaders={}\n",
    "train_df = pd.concat([partitions[\"train\"], ref_df])\n",
    "val_df = pd.concat([partitions[\"val\"], ref_df])\n",
    "labelcol=\"label\"\n",
    "train_dataset = PillImages(train_df, \"train\", labelcol=labelcol, label_encoder=label_encoder)\n",
    "val_dataset = PillImages(val_df, \"val\", labelcol=labelcol, label_encoder=label_encoder)\n",
    "dataloaders[\"train\"] = DataLoader(train_dataset, batch_sampler=BalancedBatchSamplerPillID(train_df, batch_size=32, labelcol=labelcol))\n",
    "dataloaders[\"val\"] = DataLoader(val_dataset, batch_sampler=BalancedBatchSamplerPillID(val_df, batch_size=32, labelcol=labelcol))\n",
    "dataloaders[\"eval\"] = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "torch.mps.empty_cache()\n",
    "log_file_path = \"./benchmark_training_logs2\"\n",
    "writer2 = SummaryWriter(log_file_path)\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "appearance_network = 'resnet50'\n",
    "pooling = 'GAvP'\n",
    "dropout = 0.0\n",
    "embedding_dim = 2048\n",
    "ce_w = 1.0\n",
    "arcface_w = 0.1\n",
    "contrastive_w = 1.0 \n",
    "triplet_w = 1.0\n",
    "focal_w = 0.0\n",
    "loss_weights = {'ce': ce_w, 'arcface': arcface_w, 'contrastive': contrastive_w, 'triplet': triplet_w, 'focal': focal_w}\n",
    "focal_gamma = 0.0\n",
    "metric_margin = 1.0\n",
    "train_with_side_labels = False\n",
    "train_with_ref_labels = False\n",
    "clip_grads = True\n",
    "shift_labels = False\n",
    "simulate_pairs = False\n",
    "path = \"./m2\"\n",
    "criterion2 = MultiheadLoss(len(label_encoder.classes_),\n",
    "            metric_margin, HardNegativePairSelector(),\n",
    "            metric_margin, RandomNegativeTripletSelector(metric_margin),\n",
    "            use_cosine=False,\n",
    "            weights=loss_weights,\n",
    "            focal_gamma=focal_gamma,\n",
    "            use_side_labels=train_with_side_labels)\n",
    "E_model2 = EmbeddingModel(network=appearance_network, pooling=pooling, dropout_p=dropout, cont_dims=embedding_dim, pretrained=True)\n",
    "model2 = MultiheadModel(E_model2, n_classes, train_with_side_labels=train_with_side_labels).to(device)\n",
    "opt2 = optim.Adam(model2.parameters(), lr=1e-4)\n",
    "lr_scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(opt2, mode='min', factor=0.1, patience=5)\n",
    "trainer2 = Trainer(device=device, model=model2, dataloaders=dataloaders, clip_gradients=clip_grads, optimizer=opt2, lr_scheduler=lr_scheduler2, criterion=criterion2, writer=writer2, eval_update_type=\"logit\", metric_type=\"euclidean\", simulate_pairs=simulate_pairs, shift_labels=shift_labels, train_with_ref_labels=train_with_ref_labels, plot_metrics_names=[\"acc_1\", \"acc_5\", \"loss\", \"micro_ap\", \"map\", \"mrr\"], path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_directory(log_file_path)\n",
    "clear_directory(\"./m2/checkpoints\")\n",
    "trainer2.train(num_epochs=20, checkpoint=3, earlystop_patience=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
